{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Grocery Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines steps to pull addresses of various grocery stores in Houston, TX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import requests\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import datetime as dt\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Name','Grocer','Address','Category']\n",
    "listing_all_tot = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEADERS = {'User-Agent':'Mozilla/5.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kroger DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kroger_addresses = pd.DataFrame(columns=['Name','Address','Zip','Store'])\n",
    "#Kroger listings\n",
    "for i in range(4):\n",
    "    BASE_URL = \"https://www.yellowpages.com/search?search_terms=kroger&geo_location_terms=Houston%2C%20TX&page=\" + str(i+1)\n",
    "    response = requests.get(BASE_URL,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "    addrs_street = soup.findAll(\"span\", { \"class\" : \"street-address\"})\n",
    "    addrs = []\n",
    "    for addr in addrs_street:\n",
    "        addrs.append(addr.text)\n",
    "    addrs_zip = soup.findAll(itemprop=\"postalCode\")\n",
    "    zips = []\n",
    "    for zipc in addrs_zip:\n",
    "        zips.append(zipc.text)\n",
    "    name_q = soup.findAll(\"a\", { \"class\" : \"business-name\"})\n",
    "    names = []\n",
    "    for n in name_q:\n",
    "        names.append(n.text)\n",
    "    addresses = pd.DataFrame(\n",
    "            {'Name':names,'Address': addrs,'Zip': zips})\n",
    "    addresses['Store'] = \"Kroger\"\n",
    "    kroger_addresses = pd.concat([kroger_addresses,addresses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kroger_addresses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Name</th>\n",
       "      <th>Store</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7747 Kirby Dr</td>\n",
       "      <td>Kroger Pharmacy</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>77030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3300 Montrose Blvd</td>\n",
       "      <td>Kroger Pharmacy</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>77006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5150 Buffalo Speedway</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>77005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352 W 43rd St</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>77018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3300 Montrose Blvd</td>\n",
       "      <td>Kroger Fresh Fare</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>77006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Address               Name   Store    Zip\n",
       "0  7747 Kirby Dr          Kroger Pharmacy    Kroger  77030\n",
       "1  3300 Montrose Blvd     Kroger Pharmacy    Kroger  77006\n",
       "2  5150 Buffalo Speedway  Kroger             Kroger  77005\n",
       "3  1352 W 43rd St         Kroger             Kroger  77018\n",
       "4  3300 Montrose Blvd     Kroger Fresh Fare  Kroger  77006"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kroger_addresses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiesta DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiesta_addresses = pd.DataFrame(columns=['Name','Address','Zip','Store'])\n",
    "#fiesta listings\n",
    "for i in range(5):\n",
    "    BASE_URL = \"https://www.yellowpages.com/search?search_terms=fiesta+mart&geo_location_terms=Houston%2C+TX&page=\" + str(i+1)\n",
    "    response = requests.get(BASE_URL,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "    addrs_street = soup.findAll(\"span\", { \"class\" : \"street-address\"})\n",
    "    addrs = []\n",
    "    for addr in addrs_street:\n",
    "        addrs.append(addr.text)\n",
    "    addrs_zip = soup.findAll(itemprop=\"postalCode\")\n",
    "    zips = []\n",
    "    for zipc in addrs_zip:\n",
    "        zips.append(zipc.text)\n",
    "    zips = [ x for x in zips if '77207' not in x ]   #custom filter \n",
    "    name_q = soup.findAll(\"a\", { \"class\" : \"business-name\"})\n",
    "    names = []\n",
    "    for n in name_q:\n",
    "        names.append(n.text)\n",
    "    names = [ x for x in names if \"Fiesta\" in x ] #custom filter\n",
    "    names = [ x for x in names if \"2016 Ford\" not in x ] #custom filter\n",
    "    names = [ x for x in names if \"Fiesta Patrias\" not in x ] #custom filter\n",
    "    addresses = pd.DataFrame(\n",
    "            {'Name':names,'Address': addrs,'Zip': zips})\n",
    "    addresses['Store'] = \"fiesta\"\n",
    "    fiesta_addresses = pd.concat([fiesta_addresses,addresses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Randalls_addresses = pd.DataFrame(columns=['Name','Address','Zip','Store'])\n",
    "#Randalls listings\n",
    "for i in range(2):\n",
    "    BASE_URL = \"https://www.yellowpages.com/search?search_terms=randalls&geo_location_terms=Houston%2C+TX&page=\" + str(i+1)\n",
    "    response = requests.get(BASE_URL,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "    addrs_street = soup.findAll(\"span\", { \"class\" : \"street-address\"})\n",
    "    addrs = []\n",
    "    for addr in addrs_street:\n",
    "        addrs.append(addr.text)\n",
    "    addrs = [ x for x in addrs if \"627 W 19th St\" not in x ] #custom filter\n",
    "    addrs = [ x for x in addrs if \"1015 W 24th St\" not in x ] #custom filter\n",
    "    addrs = [ x for x in addrs if \"1111 Heights Blvd\" not in x ] #custom filter\n",
    "    addrs_zip = soup.findAll(itemprop=\"postalCode\")\n",
    "    zips = []\n",
    "    for zipc in addrs_zip:\n",
    "        zips.append(zipc.text)\n",
    "    zips = [ x for x in zips if '77008' not in x ]   #custom filter \n",
    "    name_q = soup.findAll(\"a\", { \"class\" : \"business-name\"})\n",
    "    names = []\n",
    "    for n in name_q:\n",
    "        names.append(n.text)\n",
    "    names = [ x for x in names if \"Randall's Executive Transportation\" not in x ] #custom filter\n",
    "    names = [ x for x in names if \"Randalls Executive Transportation Service\" not in x ] #custom filter\n",
    "    names = [ x for x in names if \"Randall Murrow Photography\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"2016 Ford\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"Randalls Patrias\" not in x ] #custom filter\n",
    "    addresses = pd.DataFrame(\n",
    "            {'Name':names,'Address': addrs,'Zip': zips})\n",
    "    addresses['Store'] = \"Randalls\"\n",
    "    Randalls_addresses = pd.concat([Randalls_addresses,addresses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEB_addresses = pd.DataFrame(columns=['Name','Address','Zip','Store'])\n",
    "#HEB listings\n",
    "for i in range(7):\n",
    "    BASE_URL = \"https://www.yellowpages.com/search?search_terms=HEB&geo_location_terms=Houston%2C+TX&page=\" + str(i+1)\n",
    "    response = requests.get(BASE_URL,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "    addrs_street = soup.findAll(\"span\", { \"class\" : \"street-address\"})\n",
    "    addrs = []\n",
    "    for addr in addrs_street:\n",
    "        addrs.append(addr.text)\n",
    "#     addrs = [ x for x in addrs if \"627 W 19th St\" not in x ] #custom filter\n",
    "#     addrs = [ x for x in addrs if \"1015 W 24th St\" not in x ] #custom filter\n",
    "#     addrs = [ x for x in addrs if \"1111 Heights Blvd\" not in x ] #custom filter\n",
    "    addrs_zip = soup.findAll(itemprop=\"postalCode\")\n",
    "    zips = []\n",
    "    for zipc in addrs_zip:\n",
    "        zips.append(zipc.text)\n",
    "#     zips = [ x for x in zips if '77008' not in x ]   #custom filter \n",
    "    name_q = soup.findAll(\"a\", { \"class\" : \"business-name\"})\n",
    "    names = []\n",
    "    for n in name_q:\n",
    "        names.append(n.text)\n",
    "#     names = [ x for x in names if \"Randall's Executive Transportation\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"HEB Executive Transportation Service\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"Randall Murrow Photography\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"2016 Ford\" not in x ] #custom filter\n",
    "#     names = [ x for x in names if \"HEB Patrias\" not in x ] #custom filter\n",
    "    addresses = pd.DataFrame(\n",
    "            {'Name':names,'Address': addrs,'Zip': zips})\n",
    "    addresses['Store'] = \"HEB\"\n",
    "    HEB_addresses = pd.concat([HEB_addresses,addresses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = \"C:/Users/David/Dropbox/Skills/Python/\\\n",
    "Projects/Real_Estate/htx_grocery_scraping/\"\n",
    "kroger_addresses.to_csv(dir+\"kroger.csv\")\n",
    "fiesta_addresses.to_csv(dir+\"fiesta.csv\")\n",
    "Randalls_addresses.to_csv(dir+\"randalls.csv\")\n",
    "HEB_addresses.to_csv(dir+\"heb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env1]",
   "language": "python",
   "name": "conda-env-env1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
